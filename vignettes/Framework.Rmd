---
title: "Simulation framework"
author: "Jens Åström"
date: "`r Sys.Date()`"
output:
  rmarkdown::pdf_document:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  tidy = T
)
```

```{r}
require(tidyverse)
#require(InsectSurvPower)
```


Insect surve scheme - Power analysis
============
For the general insect survey power analysis, the basic idea is to 
1.  first create a general framework that simulates insect communities throughout the country,
2.  use this method to generate many simulated insect communities under different scenarios
3.  sample this community, mimicking various survey schemes
4.  calculate statistics on the power and general accuracy of the survey scheme.

The best case scenario would be to simulate the communities in a way that is as similar as possible to a future model of the findings in the samples. Then we could feed the parameter estimates from these models back to the simulation routine to update the power analysis. 


**I'm currently contemplating two different approaches to simulate the occurrences.**

1.  Simulate measurement values for each SSB 500 grid, based on predictor variables for each grid cell. These might include polynomials on lat and lon, to control for spatial autocorrelation not covered by the explanatory data. 
2.  For each species, simulate a species distribution, which collectively adds up to local communities. This is a desired end product, but might be more difficult. It includes more or less coherent distributions for each species. However, the simulation algorithm is probably far from the later used distribution models.

Probably the 1st is the most workable.


Sandbox on workflow
===============

Load map on 10km scale
--------------

```{r}
#postgresConnect()
#map10km <- getSSBGrid()
data(map10km)
```

```{r}
map10km
plot(map10km["kommune"], key.pos = NULL)
```

Add variable column to the map
-------------

```{r}
mapOcc5years <- createOccProb(map10km, 
                              intercept = 0.5,
                              sigmaFylke = 0.4, 
                              sigmaKommune = 0.1, 
                              sigmaGrid = 0.05,
                              nYears = 5,
                              interceptTrend = -0.05,
                              sigmaFylkeTrend = 0.01,
                              sigmaKommuneTrend = 0.01,
                              sortGrid = F, 
                              sortFylke = F, 
                              sortKommune = F)

mapOcc5years %>% 
  filter(year == 1) %>%
  select(prob) %>% 
  plot()


```
```{r}
mapOcc5years %>% 
  filter(year == 5) %>%
  select(prob) %>% 
  plot()

```




Sample the map for species
---------------

```{r}
testSample <- sampleBin(map10km, column = "prob", nSites = 400, nObs = 1)
plot(testSample["nFound"])
```



```{r}
sampHordaland <- sampleBin(map10km, column = "prob", nSites = 100, nObs = 1, subFylke = "Hordaland")

plot(sampHordaland["nFound"])

```


Model the findings
----------------


```{r}
require(lme4)
mod1 <- glmer(nFound ~ 1 + (1|fylke) + (1|kommune), family = "binomial", data = testSample)

summary(mod1)

```
The estimates are reasonable but not exactly perfect. We can see how the improve when we add the number of observations per grid cell.


```{r}
obs10Sample <- sampleBin(map10km, column = "prob", nSites = 400, nObs = 10)
plot(obs10Sample["nFound"])
```

```{r}
require(lme4)
mod2 <- glmer(cbind(nFound, nVisits - nFound) ~ 1 + (1|fylke) + (1|kommune), family = "binomial", data = obs10Sample)

summary(mod2)

```

Let's see what happens if we drastically increase the number of grid cells sampled


```{r}
bigSample <- sampleBin(map10km, column = "prob", nSites = 4000, nObs = 10)
plot(bigSample["nFound"])
```

```{r}
mod3 <- glmer(cbind(nFound, nVisits - nFound) ~ 1 + (1|fylke) + (1|kommune), family = "binomial", data = bigSample)

summary(mod3)

```

Not much different estistimates than from between a sample of 400 and 4000 grid cells. 


Time trends
---------

```{r}
years5 <- createOccProb(map10km, 
                              intercept = 0.5,
                              sigmaFylke = 0.4, 
                              sigmaKommune = 0.1, 
                              sigmaGrid = 0.05, 
                              sortGrid = F, 
                              sortFylke = F, 
                              sortKommune = F,
                              nYears = 5,
                              interceptTrend = -0.05,
                        sigmaFylkeTrend = 0.02,
                        sigmaKommuneTrend = 0)

```
```{r}
sample5years <- sampleBin(years5, column = "prob", nSites = 4000, nObs = 10)
```

```{r}
require(lme4)
mod4 <- glmer(cbind(nFound, nVisits - nFound) ~ year + (year|fylke) + (1|kommune), family = "binomial", data = sample5years)

summary(mod4)

```

Looks pretty good. Time trend rather well estimated. This corresponds to a cumulative decrease of about 22% over 5 years.
